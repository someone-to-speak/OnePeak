"use client";

import { Message } from "@/app/types/chatBotType/chatBotType";
import { convertSpeechToText, getChatResponse } from "@/utils/chatbot/chatBotApi";
import { useEffect, useRef, useState } from "react";
import { useRouter, useSearchParams } from "next/navigation";

const ChatMessage = () => {
  const [messages, setMessages] = useState<Message[]>([]);
  const [userInput, setUserInput] = useState<string>("");

  const [isRecording, setIsRecording] = useState<boolean>(false);
  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const chuncksRef = useRef<Blob[]>([]);

  const router = useRouter();

  // ì„ íƒí•œ "ì˜¤ëŠ˜ì˜ í•™ìŠµ" ë°ì´í„° ë°›ì•„ì˜¤ê¸°
  const searchParams = useSearchParams();
  const situation = searchParams?.get("situation") as string;
  const level = Number(searchParams?.get("level"));

  // ì±—ë´‡ì˜ ì²« ë©”ì„¸ì§€ ì¶”ê°€
  const initiateChat = () => {
    const initialMessage: Message = {
      role: "system",
      content: "ì•ˆë…•í•˜ì„¸ìš”! ì¤€ë¹„ê°€ ë˜ì…¨ë‹¤ë©´ startë¼ê³  ì…ë ¥í•´ì£¼ì„¸ìš”!"
    };
    setMessages([initialMessage]);
  };

  useEffect(() => {
    initiateChat();
  }, []);

  // ì±—ë´‡ê³¼ ëŒ€í™”í•˜ê¸°
  const sendMessage = async (e: React.FormEvent<HTMLFormElement>) => {
    e.preventDefault();

    // ì‚¬ìš©ì ë©”ì„¸ì§€ ì¶”ê°€
    const userMessage: Message = {
      role: "user",
      content: userInput
    };

    const newMessages: Message[] = [...messages, userMessage];

    setMessages(newMessages);
    setUserInput("");

    // ì±—ë´‡ì˜ ì‘ë‹µ ê°€ì ¸ì˜¤ê¸°
    if (situation && level !== undefined) {
      const botResponse = await getChatResponse(newMessages, situation, level);

      if (botResponse) {
        const botMessage: Message = { role: "assistant", content: botResponse };

        // ì±—ë´‡ ë©”ì„¸ì§€ ì¶”ê°€
        setMessages((prevMessages) => [...prevMessages, botMessage]);
      }
    }
  };

  // ìŒì„± ë…¹ìŒ ì‹œì‘
  const startRecording = async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({
        audio: {
          channelCount: 1,
          sampleRate: 16000
        }
      });

      // ë¸Œë¼ìš°ì €ê°€ ì§€ì›í•˜ëŠ” mimeType í™•ì¸
      let mimeType = "audio/webm";
      if (MediaRecorder.isTypeSupported("audio/webm")) {
        mimeType = "audio/webm";
      } else if (MediaRecorder.isTypeSupported("audio/ogg")) {
        mimeType = "audio/ogg";
      }
      // ì˜¤ë””ì˜¤ í˜•ì‹ì„ ëª…ì‹œì ìœ¼ë¡œ ì§€ì •
      const mediaRecorder = new MediaRecorder(stream, {
        mimeType: mimeType
      });

      mediaRecorderRef.current = mediaRecorder;
      chuncksRef.current = [];

      mediaRecorder.ondataavailable = (e) => {
        if (e.data.size > 0) {
          chuncksRef.current.push(e.data);
        }
      };

      mediaRecorder.onstop = async () => {
        const audioBlob = new Blob(chuncksRef.current, { type: mimeType });
        console.log("ìµœì¢… ì˜¤ë””ì˜¤ íƒ€ì…: ", audioBlob.type); // ë””ë²„ê¹…ìš©

        try {
          const audioBlob = new Blob(chuncksRef.current, { type: "audio/webm" });
          const audioFile = new File([audioBlob], "audio.webm", {
            type: "audio/webm"
          });

          // íŒŒì¼ í¬ê¸°ì™€ í˜•ì‹ í™•ì¸
          console.log("ë…¹ìŒëœ íŒŒì¼ ì •ë³´:", {
            size: audioFile.size,
            type: audioFile.type,
            name: audioFile.name
          });

          // ë¹ˆ íŒŒì¼ì¸ì§€ í™•ì¸
          if (audioFile.size === 0) {
            throw new Error("ë…¹ìŒëœ íŒŒì¼ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤");
          }

          const text = await convertSpeechToText(audioFile);
          setUserInput(text);
        } catch (error) {
          console.error("ìŒì„± ë³€í™˜ ì‹¤íŒ¨:", error);
          alert("ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ëŠ”ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ");
        }
      };

      mediaRecorder.start(1000);
      setIsRecording(true);
    } catch (error) {
      console.log("ìŒì„± ë³€í™˜ ì‹¤íŒ¨: ", error);
      alert("ë§ˆì´í¬ ì ‘ê·¼ì— ì‹¤íŒ¨í•˜ì˜€ìŠµë‹ˆë‹¤.");
    }
  };

  // ìŒì„± ë…¹ìŒ ì¤‘ì§€
  const stopRecording = () => {
    if (mediaRecorderRef.current && isRecording) {
      mediaRecorderRef.current.stop();
      setIsRecording(false);

      // ìŠ¤íŠ¸ë¦¼ ì •ì§€
      mediaRecorderRef.current.stream.getTracks().forEach((track) => track.stop());
    }
  };

  return (
    <div className="flex flex-col h-screen w-full mx-auto bg-gray-100">
      <div className="flex-grow overflow-y-auto p-4 mb-16">
        <div className="flex">
          <button onClick={() => router.back()} className="mr-5">
            ğŸ”™
          </button>
          <h1 className="font-bold">{situation}</h1>
        </div>
        {messages.map((msg, index) => (
          <div key={index} className={msg.role}>
            <strong>{msg.role === "user" ? "ë‚˜" : "ì±—ë´‡"}</strong>
            <div className="border border-spacing-10 text-green-500 p-5">{msg.content}</div>
          </div>
        ))}
      </div>
      <div className="overflow-y-auto"></div>
      <div></div>
      <form className="sticky bottom-[55px] flex w-full bg-gray-200 p-4" onSubmit={sendMessage}>
        <input
          className="flex-grow p-2 rounded border border-gray-400"
          type="text"
          value={userInput}
          onChange={(e) => setUserInput(e.target.value)}
          placeholder="ë©”ì„¸ì§€ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”."
        />
        <button
          type="button"
          className={`ml-2 px-4 py-2 rounded ${isRecording ? "bg-red-500" : "bg-gray-500"} text-white`}
          onClick={isRecording ? stopRecording : startRecording}
        >
          {isRecording ? "ğŸ¤ ì¤‘ì§€" : "ğŸ¤ ìŒì„±ì…ë ¥"}
        </button>
        <button className="ml-2 px-4 py-2 bg-blue-500 text-white rounded" type="submit">
          ì „ì†¡
        </button>
      </form>
    </div>
  );
};

export default ChatMessage;
